{"cells":[{"cell_type":"markdown","metadata":{"id":"SMGji-xvRhOG"},"source":["# AIPI531: Homework 3\n"]},{"cell_type":"markdown","metadata":{"id":"QwVXcP-QVlYD"},"source":["## Install required packages"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4552,"status":"ok","timestamp":1702405099170,"user":{"displayName":"Tianyi Hu","userId":"16536767052504761274"},"user_tz":300},"id":"E5ACnsIsVqM6","outputId":"28e3fa29-7e41-4de1-87cf-71ed8c5e6a4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: trfl==1.2.0 in /usr/local/lib/python3.10/dist-packages (1.2.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl==1.2.0) (1.4.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl==1.2.0) (0.1.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from trfl==1.2.0) (1.23.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl==1.2.0) (1.16.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl==1.2.0) (1.14.1)\n"]}],"source":["! python3 -m pip install trfl==1.2.0"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":212,"status":"ok","timestamp":1702405099378,"user":{"displayName":"Tianyi Hu","userId":"16536767052504761274"},"user_tz":300},"id":"N6oxGd5CyBNs"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"KzOJ2UUmRlxs"},"source":["## Mount file system"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1875,"status":"ok","timestamp":1702405104181,"user":{"displayName":"Tianyi Hu","userId":"16536767052504761274"},"user_tz":300},"id":"43PcjF4xEzVC","outputId":"a7cf7b39-e785-4b8b-b353-01122ccbeccc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive folder\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":174,"status":"ok","timestamp":1702405104349,"user":{"displayName":"Tianyi Hu","userId":"16536767052504761274"},"user_tz":300},"id":"tv6d_xssR0fH","outputId":"4d52f595-d3a0-49d4-eab1-22c55227c543"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Courses/AIPI531/HW3/SA2C_code/Kaggle\n","data\t\t      __pycache__\t\t   SASRecModules.py\t    split_data.py\n","DQN_NS.py\t      replay_buffer.py\t\t   SNQN_AddFeatures_new.py  test.py\n","NextItNetModules.py   report_SNQN_AddFeatures.txt  SNQN_AddFeatures.py\t    upgradeLog.txt\n","pop.py\t\t      report_SNQN.txt\t\t   SNQN_new.py\t\t    utility.py\n","preprocess_kaggle.py  SA2C.py\t\t\t   SNQN.py\n"]}],"source":["# change current directory to the project folder\n","# The original source code could be found from:\n","# https://drive.google.com/file/d/185KB520pBLgwmiuEe7JO78kUwUL_F45t/\n","PROJ_DIR = '/content/drive/My Drive/Courses/AIPI531/HW3/SA2C_code/Kaggle'\n","%cd $PROJ_DIR\n","! ls"]},{"cell_type":"markdown","metadata":{"id":"Gmu5H-KAFLol"},"source":["## Upgrade Tensorflow version 1-->2\n","\n","Need to manually modify the original source code\n","\n","1.   Disable eager execution by adding the following code on the first line of the init function `tf.compat.v1.disable_eager_execution()`\n","2.   Replace `tf.contrib.layers.fully_connected` with `tf.compat.v1.layers.dense`\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4371,"status":"ok","timestamp":1702362334755,"user":{"displayName":"Tianyi Hu","userId":"16536767052504761274"},"user_tz":300},"id":"psbhE6ePEzVE","outputId":"f38fb72d-fac7-4c1e-a939-1cb84bceefd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-12-12 06:25:30.729300: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-12 06:25:30.729360: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-12 06:25:30.729407: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-12 06:25:30.737609: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-12 06:25:31.951386: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","INFO line 68:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 71:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n","INFO line 73:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 74:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","WARNING line 78:29: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","INFO line 81:46: Renamed 'tf.nn.dynamic_rnn' to 'tf.compat.v1.nn.dynamic_rnn'\n","INFO line 82:20: Renamed 'tf.contrib.rnn.GRUCell' to 'tf.compat.v1.nn.rnn_cell.GRUCell'\n","INFO line 89:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n","INFO line 99:25: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n","\n","INFO line 99:25: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n","INFO line 102:40: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n","INFO line 105:31: Added keywords to args of function 'tf.nn.conv2d'\n","INFO line 105:31: Renamed keyword argument for tf.nn.conv2d from filter to filters\n","INFO line 116:33: Added keywords to args of function 'tf.nn.max_pool'\n","INFO line 116:33: Renamed keyword argument for tf.nn.max_pool from value to input\n","INFO line 116:33: Renamed 'tf.nn.max_pool' to 'tf.nn.max_pool2d'\n","INFO line 129:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n","\n","INFO line 129:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n","INFO line 131:36: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n","INFO line 133:27: Added keywords to args of function 'tf.nn.conv2d'\n","INFO line 133:27: Renamed keyword argument for tf.nn.conv2d from filter to filters\n","INFO line 144:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n","\n","INFO line 144:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n","INFO line 145:41: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n","INFO line 150:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n","WARNING line 159:36: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","WARNING line 174:26: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","INFO line 179:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n","INFO line 181:27: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n","INFO line 189:25: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n","INFO line 222:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 224:34: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 226:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 227:37: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 229:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 230:28: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 232:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 233:44: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 252:23: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n","INFO line 257:17: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n","INFO line 258:47: Renamed 'tf.random_normal' to 'tf.random.normal'\n","INFO line 260:45: Renamed 'tf.random_normal' to 'tf.random.normal'\n","INFO line 345:4: Renamed 'tf.reset_default_graph' to 'tf.compat.v1.reset_default_graph'\n","INFO line 356:9: Renamed 'tf.Session' to 'tf.compat.v1.Session'\n","INFO line 358:17: Renamed 'tf.global_variables_initializer' to 'tf.compat.v1.global_variables_initializer'\n","TensorFlow 2.0 Upgrade Script\n","-----------------------------\n","Converted 1 files\n","Detected 3 issues that require attention\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","File: SNQN.py\n","--------------------------------------------------------------------------------\n","SNQN.py:78:29: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","SNQN.py:159:36: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","SNQN.py:174:26: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","\n","\n","Make sure to read the detailed log 'report_SNQN.txt'\n","\n"]}],"source":["!tf_upgrade_v2 \\\n","  --infile 'SNQN.py' \\\n","  --outfile 'SNQN_new.py' \\\n","  --reportfile report_SNQN.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6561,"status":"ok","timestamp":1702362341313,"user":{"displayName":"Tianyi Hu","userId":"16536767052504761274"},"user_tz":300},"id":"sYNiLM5ozVss","outputId":"8fada226-3165-4d61-8d23-b71b3b2bed75"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-12-12 06:25:35.011422: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-12 06:25:35.011477: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-12 06:25:35.011515: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-12 06:25:35.022861: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-12 06:25:36.695985: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","INFO line 71:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 77:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n","INFO line 79:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 80:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","WARNING line 84:29: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","INFO line 87:46: Renamed 'tf.nn.dynamic_rnn' to 'tf.compat.v1.nn.dynamic_rnn'\n","INFO line 88:20: Renamed 'tf.contrib.rnn.GRUCell' to 'tf.compat.v1.nn.rnn_cell.GRUCell'\n","INFO line 95:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n","INFO line 105:25: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n","\n","INFO line 105:25: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n","INFO line 108:40: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n","INFO line 111:31: Added keywords to args of function 'tf.nn.conv2d'\n","INFO line 111:31: Renamed keyword argument for tf.nn.conv2d from filter to filters\n","INFO line 122:33: Added keywords to args of function 'tf.nn.max_pool'\n","INFO line 122:33: Renamed keyword argument for tf.nn.max_pool from value to input\n","INFO line 122:33: Renamed 'tf.nn.max_pool' to 'tf.nn.max_pool2d'\n","INFO line 135:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n","\n","INFO line 135:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n","INFO line 137:36: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n","INFO line 139:27: Added keywords to args of function 'tf.nn.conv2d'\n","INFO line 139:27: Renamed keyword argument for tf.nn.conv2d from filter to filters\n","INFO line 150:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n","\n","INFO line 150:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n","INFO line 151:41: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n","INFO line 156:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n","WARNING line 165:36: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","WARNING line 180:26: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","INFO line 185:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n","INFO line 187:27: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n","INFO line 195:25: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n","INFO line 240:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 242:34: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 244:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 245:37: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 247:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 248:28: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 250:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 251:44: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n","INFO line 271:23: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n","INFO line 276:17: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n","INFO line 277:47: Renamed 'tf.random_normal' to 'tf.random.normal'\n","INFO line 279:45: Renamed 'tf.random_normal' to 'tf.random.normal'\n","INFO line 367:4: Renamed 'tf.reset_default_graph' to 'tf.compat.v1.reset_default_graph'\n","INFO line 380:9: Renamed 'tf.Session' to 'tf.compat.v1.Session'\n","INFO line 382:17: Renamed 'tf.global_variables_initializer' to 'tf.compat.v1.global_variables_initializer'\n","TensorFlow 2.0 Upgrade Script\n","-----------------------------\n","Converted 1 files\n","Detected 3 issues that require attention\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","File: SNQN_AddFeatures.py\n","--------------------------------------------------------------------------------\n","SNQN_AddFeatures.py:84:29: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","SNQN_AddFeatures.py:165:36: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","SNQN_AddFeatures.py:180:26: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n","\n","\n","Make sure to read the detailed log 'report_SNQN_AddFeatures.txt'\n","\n"]}],"source":["!tf_upgrade_v2 \\\n","  --infile 'SNQN_AddFeatures.py' \\\n","  --outfile 'SNQN_AddFeatures_new.py' \\\n","  --reportfile report_SNQN_AddFeatures.txt"]},{"cell_type":"markdown","metadata":{"id":"7kJIALxDxD8Y"},"source":["## Without item features"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4554270,"status":"ok","timestamp":1702333771982,"user":{"displayName":"Tianyi Hu","userId":"16536767052504761274"},"user_tz":300},"id":"pL5755OhFVD3","outputId":"9862106b-1228-4d8d-e198-8e032bedbb4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-12-11 20:09:14.404912: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-11 20:09:14.404961: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-11 20:09:14.404991: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-11 20:09:14.412946: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-11 20:09:15.629118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_new.py:82: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","WARNING:tensorflow:From /content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_new.py:81: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","2023-12-11 20:09:19.885897: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-11 20:09:20.438991: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-11 20:09:20.439272: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-11 20:09:20.440985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-11 20:09:20.441183: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-11 20:09:20.441320: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-11 20:09:22.845326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-11 20:09:22.845672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-11 20:09:22.845809: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-12-11 20:09:22.845877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-11 20:09:22.846016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14582 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_new.py:212: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_new.py:218: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","2023-12-11 20:09:30.226041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-11 20:09:30.226323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-11 20:09:30.226489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-11 20:09:30.226698: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-11 20:09:30.226857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-11 20:09:30.226985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14582 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","2023-12-11 20:09:30.251165: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 0.800000\n","clicks hr ndcg @ 5 : 0.000034, 0.000018\n","purchase hr and ndcg @5 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 1.800000\n","clicks hr ndcg @ 10 : 0.000076, 0.000031\n","purchase hr and ndcg @10 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 2.600000\n","clicks hr ndcg @ 15 : 0.000110, 0.000040\n","purchase hr and ndcg @15 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 4.000000\n","clicks hr ndcg @ 20 : 0.000169, 0.000054\n","purchase hr and ndcg @20 : 0.000000, 0.000000\n","#############################################################\n","the loss in 200th batch is: 10.788746\n","the loss in 400th batch is: 10.504535\n","the loss in 600th batch is: 10.592226\n","the loss in 800th batch is: 10.418790\n","the loss in 1000th batch is: 10.373816\n","the loss in 1200th batch is: 10.341665\n","the loss in 1400th batch is: 10.040976\n","the loss in 1600th batch is: 10.007029\n","the loss in 1800th batch is: 9.379388\n","the loss in 2000th batch is: 9.530177\n","the loss in 2200th batch is: 9.643448\n","the loss in 2400th batch is: 9.266416\n","the loss in 2600th batch is: 9.424729\n","the loss in 2800th batch is: 9.207629\n","the loss in 3000th batch is: 9.096310\n","the loss in 3200th batch is: 8.842989\n","the loss in 3400th batch is: 9.034516\n","the loss in 3600th batch is: 9.071392\n","the loss in 3800th batch is: 8.594039\n","the loss in 4000th batch is: 8.798531\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 5913.600000\n","clicks hr ndcg @ 5 : 0.169501, 0.134111\n","purchase hr and ndcg @5 : 0.359667, 0.306278\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 6814.200000\n","clicks hr ndcg @ 10 : 0.199322, 0.143780\n","purchase hr and ndcg @10 : 0.396522, 0.318273\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 7328.200000\n","clicks hr ndcg @ 15 : 0.216566, 0.148345\n","purchase hr and ndcg @15 : 0.416556, 0.323557\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 7684.200000\n","clicks hr ndcg @ 20 : 0.228864, 0.151250\n","purchase hr and ndcg @20 : 0.428841, 0.326454\n","#############################################################\n","the loss in 4200th batch is: 8.322620\n","the loss in 4400th batch is: 8.516917\n","the loss in 4600th batch is: 8.355989\n","the loss in 4800th batch is: 8.460208\n","the loss in 5000th batch is: 7.884090\n","the loss in 5200th batch is: 7.795734\n","the loss in 5400th batch is: 8.000345\n","the loss in 5600th batch is: 7.951880\n","the loss in 5800th batch is: 7.932066\n","the loss in 6000th batch is: 7.791362\n","the loss in 6200th batch is: 7.720364\n","the loss in 6400th batch is: 8.217935\n","the loss in 6600th batch is: 7.332315\n","the loss in 6800th batch is: 7.551184\n","the loss in 7000th batch is: 7.336651\n","the loss in 7200th batch is: 7.891696\n","the loss in 7400th batch is: 7.272047\n","the loss in 7600th batch is: 7.384851\n","the loss in 7800th batch is: 7.388782\n","the loss in 8000th batch is: 7.181529\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8017.000000\n","clicks hr ndcg @ 5 : 0.232955, 0.184246\n","purchase hr and ndcg @5 : 0.473445, 0.407615\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 9230.400000\n","clicks hr ndcg @ 10 : 0.275235, 0.197941\n","purchase hr and ndcg @10 : 0.513703, 0.420597\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 9900.000000\n","clicks hr ndcg @ 15 : 0.298506, 0.204101\n","purchase hr and ndcg @15 : 0.536194, 0.426538\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 10366.600000\n","clicks hr ndcg @ 20 : 0.314802, 0.207951\n","purchase hr and ndcg @20 : 0.551503, 0.430152\n","#############################################################\n","the loss in 8200th batch is: 6.852190\n","the loss in 8400th batch is: 6.749616\n","the loss in 8600th batch is: 7.111637\n","the loss in 8800th batch is: 6.982988\n","the loss in 9000th batch is: 6.504706\n","the loss in 9200th batch is: 6.753013\n","the loss in 9400th batch is: 6.562710\n","the loss in 9600th batch is: 6.793602\n","the loss in 9800th batch is: 7.042982\n","the loss in 10000th batch is: 6.828664\n","the loss in 10200th batch is: 6.930991\n","the loss in 10400th batch is: 6.835599\n","the loss in 10600th batch is: 6.826793\n","the loss in 10800th batch is: 6.460709\n","the loss in 11000th batch is: 6.589398\n","the loss in 11200th batch is: 6.385023\n","the loss in 11400th batch is: 6.315124\n","the loss in 11600th batch is: 6.526646\n","the loss in 11800th batch is: 6.473285\n","the loss in 12000th batch is: 6.500184\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8787.600000\n","clicks hr ndcg @ 5 : 0.255169, 0.199441\n","purchase hr and ndcg @5 : 0.519751, 0.440349\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10136.200000\n","clicks hr ndcg @ 10 : 0.301684, 0.214498\n","purchase hr and ndcg @10 : 0.566623, 0.455630\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 10882.000000\n","clicks hr ndcg @ 15 : 0.328048, 0.221478\n","purchase hr and ndcg @15 : 0.589681, 0.461732\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 11374.400000\n","clicks hr ndcg @ 20 : 0.345350, 0.225562\n","purchase hr and ndcg @20 : 0.605368, 0.465429\n","#############################################################\n","the loss in 12200th batch is: 6.448835\n","the loss in 12400th batch is: 6.415452\n","the loss in 12600th batch is: 6.111263\n","the loss in 12800th batch is: 6.138548\n","the loss in 13000th batch is: 6.260540\n","the loss in 13200th batch is: 6.603885\n","the loss in 13400th batch is: 6.247716\n","the loss in 13600th batch is: 6.352149\n","the loss in 13800th batch is: 6.250634\n","the loss in 14000th batch is: 5.860389\n","the loss in 14200th batch is: 6.078033\n","the loss in 14400th batch is: 6.258766\n","the loss in 14600th batch is: 5.993052\n","the loss in 14800th batch is: 6.037095\n","the loss in 15000th batch is: 6.131647\n","the loss in 15200th batch is: 5.796871\n","the loss in 15400th batch is: 5.992221\n","the loss in 15600th batch is: 5.711697\n","the loss in 15800th batch is: 6.022665\n","the loss in 16000th batch is: 6.019231\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 8956.200000\n","clicks hr ndcg @ 5 : 0.260435, 0.203404\n","purchase hr and ndcg @5 : 0.528067, 0.447032\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10434.200000\n","clicks hr ndcg @ 10 : 0.311235, 0.219889\n","purchase hr and ndcg @10 : 0.580231, 0.463935\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11210.400000\n","clicks hr ndcg @ 15 : 0.338292, 0.227060\n","purchase hr and ndcg @15 : 0.605935, 0.470744\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 11730.200000\n","clicks hr ndcg @ 20 : 0.356795, 0.231433\n","purchase hr and ndcg @20 : 0.621433, 0.474424\n","#############################################################\n","the loss in 16200th batch is: 6.030902\n","the loss in 16400th batch is: 5.932889\n","the loss in 16600th batch is: 5.978888\n","the loss in 16800th batch is: 6.016111\n","the loss in 17000th batch is: 6.127600\n","the loss in 17200th batch is: 5.858068\n","the loss in 17400th batch is: 5.762507\n","the loss in 17600th batch is: 6.610218\n","the loss in 17800th batch is: 6.066659\n","the loss in 18000th batch is: 6.203566\n","the loss in 18200th batch is: 5.808925\n","the loss in 18400th batch is: 5.418415\n","the loss in 18600th batch is: 5.196507\n","the loss in 18800th batch is: 5.475044\n","the loss in 19000th batch is: 5.794219\n","the loss in 19200th batch is: 5.859072\n","the loss in 19400th batch is: 6.010473\n","the loss in 19600th batch is: 5.790483\n","the loss in 19800th batch is: 6.031195\n","the loss in 20000th batch is: 5.861674\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 9069.800000\n","clicks hr ndcg @ 5 : 0.265405, 0.205310\n","purchase hr and ndcg @5 : 0.527311, 0.443277\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 10542.000000\n","clicks hr ndcg @ 10 : 0.315326, 0.221488\n","purchase hr and ndcg @10 : 0.582310, 0.461149\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 11349.600000\n","clicks hr ndcg @ 15 : 0.343415, 0.228929\n","purchase hr and ndcg @15 : 0.609337, 0.468290\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 11877.600000\n","clicks hr ndcg @ 20 : 0.362306, 0.233394\n","purchase hr and ndcg @20 : 0.624646, 0.471912\n","#############################################################\n","the loss in 20200th batch is: 5.398901\n","the loss in 20400th batch is: 5.810058\n","the loss in 20600th batch is: 5.402518\n","the loss in 20800th batch is: 5.645494\n","the loss in 21000th batch is: 5.575197\n","the loss in 21200th batch is: 5.464173\n","the loss in 21400th batch is: 5.453675\n","the loss in 21600th batch is: 5.417806\n","the loss in 21800th batch is: 5.506438\n","the loss in 22000th batch is: 5.280734\n","the loss in 22200th batch is: 5.462863\n","the loss in 22400th batch is: 5.275962\n","the loss in 22600th batch is: 5.378338\n","the loss in 22800th batch is: 5.149721\n","the loss in 23000th batch is: 5.393022\n"]}],"source":["! python SNQN_new.py --model=GRU --epoch=6"]},{"cell_type":"markdown","metadata":{"id":"tbkHx7wrFVxO"},"source":["## With features"]},{"cell_type":"code","source":[],"metadata":{"id":"tq0zfz-na1EI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TWUJe_bn73Pq"},"source":["Need to download the full dataset from:\n","https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset\n","\n","Put the dataset under the folder `AIPI531\\HW3\\SA2C_code\\Kaggle\\data`"]},{"cell_type":"markdown","metadata":{"id":"bF8s-o2Bxg3S"},"source":["### Need to preprocess data to genrerate features"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"x3V1EcMMxWu1","executionInfo":{"status":"ok","timestamp":1702365770613,"user_tz":300,"elapsed":294,"user":{"displayName":"Tianyi Hu","userId":"16536767052504761274"}}},"outputs":[],"source":["def load_dataframes(sorted_events, n_files=2, path_name=\"./item_properties_part\"):\n","    \"\"\"\n","    Load CSV data into pandas DataFrames.\n","    \"\"\"\n","    # Load sorted events data from a CSV file into a DataFrame\n","    sorted_events_df = pd.read_csv(sorted_events)\n","    # Load item properties data from multiple CSV files into a list of DataFrames\n","    dfs = [pd.read_csv(f\"{path_name}{i + 1}.csv\") for i in range(n_files)]\n","    # Concatenate all item properties DataFrames into a single DataFrame\n","    item_features_df = pd.concat(dfs, ignore_index=True)\n","    return sorted_events_df, item_features_df\n","\n","def preprocess_item_features(sorted_events_df, item_features_df):\n","    \"\"\"\n","    Preprocess item features DataFrame by filtering and cleaning data.\n","    \"\"\"\n","    # Get unique item IDs from sorted events DataFrame\n","    unique_item_ids = sorted_events_df[\"item_id\"].unique()\n","    # Filter item features DataFrame for items present in sorted events\n","    item_features_df = item_features_df[item_features_df[\"itemid\"].isin(unique_item_ids)].drop_duplicates()\n","    # Drop rows where item is marked as unavailable\n","    item_features_df = item_features_df[~((item_features_df[\"property\"] == \"available\") & (item_features_df[\"value\"] == '0'))]\n","    # Create a new column combining property and value as a single string\n","    item_features_df[\"property_value\"] = item_features_df[\"property\"].str.strip() + item_features_df[\"value\"].str.strip()\n","    # Drop timestamp column and any duplicate rows\n","    return item_features_df.drop([\"timestamp\"], axis=1).drop_duplicates()\n","\n","def one_hot_encode_features(sorted_events_df, item_features_df, top_features=500):\n","    \"\"\"\n","    One hot encode the top item features.\n","    \"\"\"\n","    # Get unique sorted item IDs and sort them\n","    unique_event_items = sorted_events_df[\"item_id\"].unique()\n","    unique_event_items.sort()\n","    # Get the top features based on occurrence\n","    properties = item_features_df[\"property_value\"].value_counts().head(top_features).index.tolist()\n","    one_hot_encoded = []\n","    itemids = []\n","\n","    # Iterate over each item and create a one-hot encoded row for its features\n","    for _, item in enumerate(unique_event_items):\n","        item_properties = set(item_features_df[item_features_df[\"itemid\"] == item][\"property_value\"].unique())\n","        encoded_row = [1 if prop in item_properties else 0 for prop in properties]\n","        one_hot_encoded.append(encoded_row)\n","        itemids.append(item)\n","\n","    print(\"One hot encoding done.\")\n","    return pd.DataFrame(one_hot_encoded), itemids\n","\n","def create_feature_matrix(sorted_events, n_files, path_name, top_features=500):\n","    \"\"\"\n","    Create and return a matrix of one hot encoded item features.\n","    \"\"\"\n","    # Load and preprocess data\n","    sorted_events_df, item_features_df = load_dataframes(sorted_events, n_files, path_name)\n","    item_features_df = preprocess_item_features(sorted_events_df, item_features_df)\n","\n","    # Perform one hot encoding of features\n","    return one_hot_encode_features(sorted_events_df, item_features_df, top_features)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":281595,"status":"ok","timestamp":1702362736966,"user":{"displayName":"Tianyi Hu","userId":"16536767052504761274"},"user_tz":300},"id":"d6Tc75WXyisG","outputId":"782773bf-ba1a-48d6-e6a0-7a51ad6e5b37"},"outputs":[{"name":"stdout","output_type":"stream","text":["One hot encoding done.\n"]}],"source":["# gernerate item features\n","df_item_feature, _ = create_feature_matrix(sorted_events='./data/sorted_events.csv', n_files=2,\n","                                           path_name=\"./data/item_properties_part\", top_features=500)\n","df_item_feature.to_csv('./data/item_features.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9070869,"status":"ok","timestamp":1702356502840,"user":{"displayName":"Tianyi Hu","userId":"16536767052504761274"},"user_tz":300},"id":"OD6F6mwXwUNh","outputId":"cc8b0844-4748-4cf5-f5c1-6b2856012d5f"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-12-12 02:17:12.913681: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-12 02:17:12.913742: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-12 02:17:12.913801: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-12 02:17:12.925654: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-12 02:17:14.633193: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:88: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","WARNING:tensorflow:From /content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:87: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","2023-12-12 02:17:22.760604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 02:17:23.261214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 02:17:23.261503: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 02:17:23.262742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 02:17:23.262946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 02:17:23.263118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 02:17:25.333819: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 02:17:25.334177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 02:17:25.334359: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-12-12 02:17:25.334478: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 02:17:25.334638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14582 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:218: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:224: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:230: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output3 = tf.compat.v1.layers.dense(self.item_features, self.hidden_size, activation=None, name=\"ce-logits-new\")\n","2023-12-12 02:17:35.202134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 02:17:35.202475: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 02:17:35.202657: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 02:17:35.202883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 02:17:35.203053: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 02:17:35.203201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14582 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","2023-12-12 02:17:35.763240: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 1.000000\n","clicks hr ndcg @ 5 : 0.000042, 0.000020\n","purchase hr and ndcg @5 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 2.800000\n","clicks hr ndcg @ 10 : 0.000118, 0.000043\n","purchase hr and ndcg @10 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 6.000000\n","clicks hr ndcg @ 15 : 0.000169, 0.000057\n","purchase hr and ndcg @15 : 0.000378, 0.000096\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 9.600000\n","clicks hr ndcg @ 20 : 0.000279, 0.000083\n","purchase hr and ndcg @20 : 0.000567, 0.000141\n","#############################################################\n","the loss in 200th batch is: 10.754436\n","the loss in 400th batch is: 10.521930\n","the loss in 600th batch is: 10.363504\n","the loss in 800th batch is: 10.405111\n","the loss in 1000th batch is: 10.236061\n","the loss in 1200th batch is: 9.940458\n","the loss in 1400th batch is: 9.893562\n","the loss in 1600th batch is: 9.673352\n","the loss in 1800th batch is: 9.769217\n","the loss in 2000th batch is: 9.661236\n","the loss in 2200th batch is: 9.517921\n","the loss in 2400th batch is: 9.685620\n","the loss in 2600th batch is: 9.429317\n","the loss in 2800th batch is: 9.160809\n","the loss in 3000th batch is: 9.382000\n","the loss in 3200th batch is: 9.356956\n","the loss in 3400th batch is: 8.787205\n","the loss in 3600th batch is: 8.617984\n","the loss in 3800th batch is: 8.831542\n","the loss in 4000th batch is: 7.973627\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 4946.400000\n","clicks hr ndcg @ 5 : 0.141303, 0.107265\n","purchase hr and ndcg @5 : 0.302967, 0.242644\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 5942.600000\n","clicks hr ndcg @ 10 : 0.172502, 0.117368\n","purchase hr and ndcg @10 : 0.351729, 0.258550\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 6515.600000\n","clicks hr ndcg @ 15 : 0.191774, 0.122469\n","purchase hr and ndcg @15 : 0.373842, 0.264389\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 6926.000000\n","clicks hr ndcg @ 20 : 0.205400, 0.125689\n","purchase hr and ndcg @20 : 0.390474, 0.268313\n","#############################################################\n","the loss in 4200th batch is: 8.119821\n","the loss in 4400th batch is: 8.486492\n","the loss in 4600th batch is: 8.606240\n","the loss in 4800th batch is: 8.123790\n","the loss in 5000th batch is: 8.267550\n","the loss in 5200th batch is: 8.058934\n","the loss in 5400th batch is: 8.098454\n","the loss in 5600th batch is: 7.785910\n","the loss in 5800th batch is: 7.510503\n","the loss in 6000th batch is: 7.632432\n","the loss in 6200th batch is: 7.598089\n","the loss in 6400th batch is: 7.590614\n","the loss in 6600th batch is: 7.763537\n","the loss in 6800th batch is: 7.359142\n","the loss in 7000th batch is: 7.498279\n","the loss in 7200th batch is: 7.129520\n","the loss in 7400th batch is: 7.368091\n","the loss in 7600th batch is: 7.275888\n","the loss in 7800th batch is: 7.137622\n","the loss in 8000th batch is: 7.525770\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 6644.000000\n","clicks hr ndcg @ 5 : 0.191664, 0.146520\n","purchase hr and ndcg @5 : 0.398601, 0.323093\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 7991.400000\n","clicks hr ndcg @ 10 : 0.235677, 0.160772\n","purchase hr and ndcg @10 : 0.456435, 0.341784\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 8771.000000\n","clicks hr ndcg @ 15 : 0.261948, 0.167725\n","purchase hr and ndcg @15 : 0.486297, 0.349676\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 9286.400000\n","clicks hr ndcg @ 20 : 0.279589, 0.171892\n","purchase hr and ndcg @20 : 0.504820, 0.354055\n","#############################################################\n","the loss in 8200th batch is: 7.151161\n","the loss in 8400th batch is: 7.565045\n","the loss in 8600th batch is: 6.974528\n","the loss in 8800th batch is: 6.960114\n","the loss in 9000th batch is: 7.124763\n","the loss in 9200th batch is: 6.728872\n","the loss in 9400th batch is: 6.695047\n","the loss in 9600th batch is: 7.335168\n","the loss in 9800th batch is: 6.803098\n","the loss in 10000th batch is: 7.099433\n","the loss in 10200th batch is: 7.244693\n","the loss in 10400th batch is: 7.063054\n","the loss in 10600th batch is: 6.607810\n","the loss in 10800th batch is: 6.907765\n","the loss in 11000th batch is: 6.197073\n","the loss in 11200th batch is: 6.552676\n","the loss in 11400th batch is: 6.703979\n","the loss in 11600th batch is: 7.012391\n","the loss in 11800th batch is: 6.743175\n","the loss in 12000th batch is: 6.522142\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 7266.000000\n","clicks hr ndcg @ 5 : 0.211401, 0.159499\n","purchase hr and ndcg @5 : 0.427896, 0.342501\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 8776.000000\n","clicks hr ndcg @ 10 : 0.260891, 0.175525\n","purchase hr and ndcg @10 : 0.491967, 0.363262\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 9611.000000\n","clicks hr ndcg @ 15 : 0.288954, 0.182952\n","purchase hr and ndcg @15 : 0.524287, 0.371879\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 10193.800000\n","clicks hr ndcg @ 20 : 0.308387, 0.187541\n","purchase hr and ndcg @20 : 0.547534, 0.377357\n","#############################################################\n","the loss in 12200th batch is: 6.444981\n","the loss in 12400th batch is: 6.601132\n","the loss in 12600th batch is: 6.189382\n","the loss in 12800th batch is: 6.711133\n","the loss in 13000th batch is: 6.504316\n","the loss in 13200th batch is: 6.798822\n","the loss in 13400th batch is: 6.042253\n","the loss in 13600th batch is: 6.147033\n","the loss in 13800th batch is: 6.047489\n","the loss in 14000th batch is: 5.787516\n","the loss in 14200th batch is: 6.577641\n","the loss in 14400th batch is: 6.036768\n","the loss in 14600th batch is: 6.226070\n","the loss in 14800th batch is: 6.410619\n","the loss in 15000th batch is: 5.855231\n","the loss in 15200th batch is: 6.195661\n","the loss in 15400th batch is: 5.856690\n","the loss in 15600th batch is: 6.274241\n","the loss in 15800th batch is: 5.917046\n","the loss in 16000th batch is: 5.734688\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 7508.800000\n","clicks hr ndcg @ 5 : 0.219380, 0.164508\n","purchase hr and ndcg @5 : 0.438102, 0.345878\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 9092.800000\n","clicks hr ndcg @ 10 : 0.271787, 0.181469\n","purchase hr and ndcg @10 : 0.503119, 0.367053\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 9991.800000\n","clicks hr ndcg @ 15 : 0.301371, 0.189301\n","purchase hr and ndcg @15 : 0.540730, 0.377034\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 10608.000000\n","clicks hr ndcg @ 20 : 0.322680, 0.194334\n","purchase hr and ndcg @20 : 0.561898, 0.382050\n","#############################################################\n","the loss in 16200th batch is: 6.161573\n","the loss in 16400th batch is: 5.828132\n","the loss in 16600th batch is: 5.688418\n","the loss in 16800th batch is: 5.445754\n","the loss in 17000th batch is: 5.755410\n","the loss in 17200th batch is: 6.327040\n","the loss in 17400th batch is: 6.163861\n","the loss in 17600th batch is: 6.036981\n","the loss in 17800th batch is: 5.847005\n","the loss in 18000th batch is: 5.282832\n","the loss in 18200th batch is: 5.789208\n","the loss in 18400th batch is: 6.170053\n","the loss in 18600th batch is: 5.686837\n","the loss in 18800th batch is: 6.106470\n","the loss in 19000th batch is: 5.662527\n","the loss in 19200th batch is: 5.682588\n","the loss in 19400th batch is: 5.849881\n","the loss in 19600th batch is: 5.653247\n","the loss in 19800th batch is: 5.862462\n","the loss in 20000th batch is: 5.594262\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 7546.600000\n","clicks hr ndcg @ 5 : 0.221696, 0.166633\n","purchase hr and ndcg @5 : 0.434889, 0.348497\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 9155.000000\n","clicks hr ndcg @ 10 : 0.274754, 0.183798\n","purchase hr and ndcg @10 : 0.501607, 0.370092\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 10042.800000\n","clicks hr ndcg @ 15 : 0.304879, 0.191781\n","purchase hr and ndcg @15 : 0.534682, 0.378839\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 10660.200000\n","clicks hr ndcg @ 20 : 0.326027, 0.196775\n","purchase hr and ndcg @20 : 0.556795, 0.384050\n","#############################################################\n","the loss in 20200th batch is: 5.404683\n","the loss in 20400th batch is: 5.603877\n","the loss in 20600th batch is: 5.738539\n","the loss in 20800th batch is: 5.521326\n","the loss in 21000th batch is: 5.540939\n","the loss in 21200th batch is: 6.197435\n","the loss in 21400th batch is: 5.390043\n","the loss in 21600th batch is: 5.823941\n","the loss in 21800th batch is: 5.913625\n","the loss in 22000th batch is: 5.825922\n","the loss in 22200th batch is: 5.400779\n","the loss in 22400th batch is: 5.543011\n","the loss in 22600th batch is: 5.653015\n","the loss in 22800th batch is: 5.628162\n","the loss in 23000th batch is: 5.794912\n"]}],"source":["! python SNQN_AddFeatures_new.py --model=GRU --epoch=6 --mix_lambda=0.1"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uIu34eJapon-","outputId":"88ac6911-3b4b-4feb-d397-e98548f43e65","executionInfo":{"status":"ok","timestamp":1702375819918,"user_tz":300,"elapsed":10021410,"user":{"displayName":"Tianyi Hu","userId":"16536767052504761274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-12-12 07:23:19.965076: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-12 07:23:19.965130: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-12 07:23:19.965175: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-12 07:23:19.972512: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-12 07:23:21.016765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:88: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","WARNING:tensorflow:From /content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:87: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","2023-12-12 07:23:29.090823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 07:23:29.640699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 07:23:29.640958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 07:23:29.642129: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 07:23:29.642343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 07:23:29.642510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 07:23:32.260936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 07:23:32.261301: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 07:23:32.261480: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-12-12 07:23:32.261583: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 07:23:32.261760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:218: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:224: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:230: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output3 = tf.compat.v1.layers.dense(self.item_features, self.hidden_size, activation=None, name=\"ce-logits-new\")\n","2023-12-12 07:23:41.628629: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 07:23:41.628928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 07:23:41.629087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 07:23:41.629336: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 07:23:41.629511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 07:23:41.629647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","2023-12-12 07:23:42.172214: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 0.400000\n","clicks hr ndcg @ 5 : 0.000017, 0.000012\n","purchase hr and ndcg @5 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 1.800000\n","clicks hr ndcg @ 10 : 0.000076, 0.000030\n","purchase hr and ndcg @10 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 4.200000\n","clicks hr ndcg @ 15 : 0.000178, 0.000057\n","purchase hr and ndcg @15 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 6.200000\n","clicks hr ndcg @ 20 : 0.000262, 0.000077\n","purchase hr and ndcg @20 : 0.000000, 0.000000\n","#############################################################\n","the loss in 200th batch is: 10.846942\n","the loss in 400th batch is: 10.723345\n","the loss in 600th batch is: 10.418430\n","the loss in 800th batch is: 10.272442\n","the loss in 1000th batch is: 10.249009\n","the loss in 1200th batch is: 9.922319\n","the loss in 1400th batch is: 9.904325\n","the loss in 1600th batch is: 9.790327\n","the loss in 1800th batch is: 9.588913\n","the loss in 2000th batch is: 9.505440\n","the loss in 2200th batch is: 9.211668\n","the loss in 2400th batch is: 9.430141\n","the loss in 2600th batch is: 9.219403\n","the loss in 2800th batch is: 9.275005\n","the loss in 3000th batch is: 8.785023\n","the loss in 3200th batch is: 8.596085\n","the loss in 3400th batch is: 9.152578\n","the loss in 3600th batch is: 8.847279\n","the loss in 3800th batch is: 8.695835\n","the loss in 4000th batch is: 8.820417\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 4172.800000\n","clicks hr ndcg @ 5 : 0.118075, 0.088336\n","purchase hr and ndcg @5 : 0.260631, 0.209077\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 5102.200000\n","clicks hr ndcg @ 10 : 0.147338, 0.097805\n","purchase hr and ndcg @10 : 0.305424, 0.223590\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 5682.400000\n","clicks hr ndcg @ 15 : 0.165985, 0.102734\n","purchase hr and ndcg @15 : 0.331695, 0.230521\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 6089.600000\n","clicks hr ndcg @ 20 : 0.178799, 0.105765\n","purchase hr and ndcg @20 : 0.351351, 0.235173\n","#############################################################\n","the loss in 4200th batch is: 8.533731\n","the loss in 4400th batch is: 8.202846\n","the loss in 4600th batch is: 8.468979\n","the loss in 4800th batch is: 7.727900\n","the loss in 5000th batch is: 7.673500\n","the loss in 5200th batch is: 8.279222\n","the loss in 5400th batch is: 8.119958\n","the loss in 5600th batch is: 7.879259\n","the loss in 5800th batch is: 8.385175\n","the loss in 6000th batch is: 7.300150\n","the loss in 6200th batch is: 7.810406\n","the loss in 6400th batch is: 7.802402\n","the loss in 6600th batch is: 7.696684\n","the loss in 6800th batch is: 7.638385\n","the loss in 7000th batch is: 7.696178\n","the loss in 7200th batch is: 7.437670\n","the loss in 7400th batch is: 7.330555\n","the loss in 7600th batch is: 7.688557\n","the loss in 7800th batch is: 7.684587\n","the loss in 8000th batch is: 7.535576\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 5736.400000\n","clicks hr ndcg @ 5 : 0.164759, 0.123103\n","purchase hr and ndcg @5 : 0.347382, 0.274020\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 7068.400000\n","clicks hr ndcg @ 10 : 0.207783, 0.137047\n","purchase hr and ndcg @10 : 0.406728, 0.293199\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 7909.800000\n","clicks hr ndcg @ 15 : 0.235187, 0.144285\n","purchase hr and ndcg @15 : 0.443205, 0.302878\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 8450.800000\n","clicks hr ndcg @ 20 : 0.253909, 0.148709\n","purchase hr and ndcg @20 : 0.461727, 0.307253\n","#############################################################\n","the loss in 8200th batch is: 7.351362\n","the loss in 8400th batch is: 7.458272\n","the loss in 8600th batch is: 7.235706\n","the loss in 8800th batch is: 7.679061\n","the loss in 9000th batch is: 7.164625\n","the loss in 9200th batch is: 7.388479\n","the loss in 9400th batch is: 7.319678\n","the loss in 9600th batch is: 6.912896\n","the loss in 9800th batch is: 6.591817\n","the loss in 10000th batch is: 7.314579\n","the loss in 10200th batch is: 7.095568\n","the loss in 10400th batch is: 7.504889\n","the loss in 10600th batch is: 6.919132\n","the loss in 10800th batch is: 6.351235\n","the loss in 11000th batch is: 6.653951\n","the loss in 11200th batch is: 6.908944\n","the loss in 11400th batch is: 6.970249\n","the loss in 11600th batch is: 6.686884\n","the loss in 11800th batch is: 6.714893\n","the loss in 12000th batch is: 6.804193\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 6298.400000\n","clicks hr ndcg @ 5 : 0.181538, 0.134300\n","purchase hr and ndcg @5 : 0.378567, 0.294730\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 7827.000000\n","clicks hr ndcg @ 10 : 0.232490, 0.150804\n","purchase hr and ndcg @10 : 0.439614, 0.314739\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 8702.200000\n","clicks hr ndcg @ 15 : 0.261618, 0.158510\n","purchase hr and ndcg @15 : 0.474768, 0.324026\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 9344.800000\n","clicks hr ndcg @ 20 : 0.283156, 0.163596\n","purchase hr and ndcg @20 : 0.499905, 0.329955\n","#############################################################\n","the loss in 12200th batch is: 6.432540\n","the loss in 12400th batch is: 6.926863\n","the loss in 12600th batch is: 6.639270\n","the loss in 12800th batch is: 6.036188\n","the loss in 13000th batch is: 6.347037\n","the loss in 13200th batch is: 6.290425\n","the loss in 13400th batch is: 6.530027\n","the loss in 13600th batch is: 6.035195\n","the loss in 13800th batch is: 6.179902\n","the loss in 14000th batch is: 6.584720\n","the loss in 14200th batch is: 6.398465\n","the loss in 14400th batch is: 6.448624\n","the loss in 14600th batch is: 6.280378\n","the loss in 14800th batch is: 6.524435\n","the loss in 15000th batch is: 6.076558\n","the loss in 15200th batch is: 6.185187\n","the loss in 15400th batch is: 6.485496\n","the loss in 15600th batch is: 5.904118\n","the loss in 15800th batch is: 6.459162\n","the loss in 16000th batch is: 6.118972\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 6506.200000\n","clicks hr ndcg @ 5 : 0.188376, 0.138576\n","purchase hr and ndcg @5 : 0.387261, 0.302209\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 8187.600000\n","clicks hr ndcg @ 10 : 0.241645, 0.155770\n","purchase hr and ndcg @10 : 0.466830, 0.327928\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 9105.000000\n","clicks hr ndcg @ 15 : 0.272683, 0.163982\n","purchase hr and ndcg @15 : 0.501418, 0.337125\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 9764.200000\n","clicks hr ndcg @ 20 : 0.295217, 0.169310\n","purchase hr and ndcg @20 : 0.525232, 0.342753\n","#############################################################\n","the loss in 16200th batch is: 6.081783\n","the loss in 16400th batch is: 5.990146\n","the loss in 16600th batch is: 6.398847\n","the loss in 16800th batch is: 6.543275\n","the loss in 17000th batch is: 6.140752\n","the loss in 17200th batch is: 5.629522\n","the loss in 17400th batch is: 6.349673\n","the loss in 17600th batch is: 5.805871\n","the loss in 17800th batch is: 6.327299\n","the loss in 18000th batch is: 5.441189\n","the loss in 18200th batch is: 5.633101\n","the loss in 18400th batch is: 5.897030\n","the loss in 18600th batch is: 5.708559\n","the loss in 18800th batch is: 5.774401\n","the loss in 19000th batch is: 5.881379\n","the loss in 19200th batch is: 5.791365\n","the loss in 19400th batch is: 6.127819\n","the loss in 19600th batch is: 5.905676\n","the loss in 19800th batch is: 5.843591\n","the loss in 20000th batch is: 5.716269\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 6623.200000\n","clicks hr ndcg @ 5 : 0.193870, 0.142764\n","purchase hr and ndcg @5 : 0.384804, 0.299338\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 8318.800000\n","clicks hr ndcg @ 10 : 0.248457, 0.160455\n","purchase hr and ndcg @10 : 0.461160, 0.324014\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 9292.400000\n","clicks hr ndcg @ 15 : 0.280434, 0.168924\n","purchase hr and ndcg @15 : 0.502174, 0.334881\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 9965.800000\n","clicks hr ndcg @ 20 : 0.302428, 0.174121\n","purchase hr and ndcg @20 : 0.531091, 0.341716\n","#############################################################\n","the loss in 20200th batch is: 5.674217\n","the loss in 20400th batch is: 6.363029\n","the loss in 20600th batch is: 5.403645\n","the loss in 20800th batch is: 6.104345\n","the loss in 21000th batch is: 5.617573\n","the loss in 21200th batch is: 5.582794\n","the loss in 21400th batch is: 5.952548\n","the loss in 21600th batch is: 5.891495\n","the loss in 21800th batch is: 5.700283\n","the loss in 22000th batch is: 5.684194\n","the loss in 22200th batch is: 5.958151\n","the loss in 22400th batch is: 5.409374\n","the loss in 22600th batch is: 5.806285\n","the loss in 22800th batch is: 5.811456\n","the loss in 23000th batch is: 5.090404\n"]}],"source":["! python SNQN_AddFeatures_new.py --model=GRU --epoch=6 --mix_lambda=0.2"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"d2CuUillKyAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702397452227,"user_tz":300,"elapsed":7927614,"user":{"displayName":"Tianyi Hu","userId":"16536767052504761274"}},"outputId":"3ea7c1d6-f629-496c-983d-ea7fff717497"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-12-12 13:58:45.547037: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-12 13:58:45.547089: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-12 13:58:45.547127: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-12 13:58:45.554651: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-12 13:58:46.595736: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:88: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n","  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n","WARNING:tensorflow:From /content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:87: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","2023-12-12 13:58:53.267474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 13:58:53.892407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 13:58:53.892697: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 13:58:53.894149: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 13:58:53.894360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 13:58:53.894546: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 13:58:56.415769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 13:58:56.415988: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 13:58:56.416108: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-12-12 13:58:56.416169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 13:58:56.416298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14582 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:218: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:224: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output2 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n","/content/drive/MyDrive/Courses/AIPI531/HW3/SA2C_code/Kaggle/SNQN_AddFeatures_new.py:230: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.output3 = tf.compat.v1.layers.dense(self.item_features, self.hidden_size, activation=None, name=\"ce-logits-new\")\n","2023-12-12 13:59:04.155331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 13:59:04.155664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 13:59:04.155890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 13:59:04.156118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 13:59:04.156300: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-12 13:59:04.156437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14582 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n","2023-12-12 13:59:04.689511: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 2.800000\n","clicks hr ndcg @ 5 : 0.000118, 0.000078\n","purchase hr and ndcg @5 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 4.400000\n","clicks hr ndcg @ 10 : 0.000186, 0.000098\n","purchase hr and ndcg @10 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 6.000000\n","clicks hr ndcg @ 15 : 0.000254, 0.000116\n","purchase hr and ndcg @15 : 0.000000, 0.000000\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 9.200000\n","clicks hr ndcg @ 20 : 0.000347, 0.000138\n","purchase hr and ndcg @20 : 0.000189, 0.000046\n","#############################################################\n","the loss in 200th batch is: 10.833483\n","the loss in 400th batch is: 10.481092\n","the loss in 600th batch is: 10.360117\n","the loss in 800th batch is: 10.523298\n","the loss in 1000th batch is: 10.140460\n","the loss in 1200th batch is: 10.170238\n","the loss in 1400th batch is: 9.579498\n","the loss in 1600th batch is: 9.986452\n","the loss in 1800th batch is: 9.634001\n","the loss in 2000th batch is: 9.669767\n","the loss in 2200th batch is: 9.372087\n","the loss in 2400th batch is: 9.530513\n","the loss in 2600th batch is: 9.076120\n","the loss in 2800th batch is: 9.607784\n","the loss in 3000th batch is: 9.103373\n","the loss in 3200th batch is: 9.170205\n","the loss in 3400th batch is: 8.885829\n","the loss in 3600th batch is: 9.094196\n","the loss in 3800th batch is: 9.028107\n","the loss in 4000th batch is: 8.627546\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 2504.600000\n","clicks hr ndcg @ 5 : 0.073141, 0.051934\n","purchase hr and ndcg @5 : 0.146286, 0.108902\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 3285.200000\n","clicks hr ndcg @ 10 : 0.096876, 0.059580\n","purchase hr and ndcg @10 : 0.187677, 0.122228\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 3763.800000\n","clicks hr ndcg @ 15 : 0.111440, 0.063436\n","purchase hr and ndcg @15 : 0.213003, 0.128960\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 4112.800000\n","clicks hr ndcg @ 20 : 0.121963, 0.065919\n","purchase hr and ndcg @20 : 0.231903, 0.133425\n","#############################################################\n","the loss in 4200th batch is: 8.390939\n","the loss in 4400th batch is: 8.342850\n","the loss in 4600th batch is: 8.516039\n","the loss in 4800th batch is: 8.776825\n","the loss in 5000th batch is: 8.427114\n","the loss in 5200th batch is: 8.332653\n","the loss in 5400th batch is: 8.218182\n","the loss in 5600th batch is: 8.347759\n","the loss in 5800th batch is: 8.196326\n","the loss in 6000th batch is: 8.104565\n","the loss in 6200th batch is: 8.231723\n","the loss in 6400th batch is: 8.078841\n","the loss in 6600th batch is: 8.214385\n","the loss in 6800th batch is: 8.500009\n","the loss in 7000th batch is: 7.424860\n","the loss in 7200th batch is: 8.074249\n","the loss in 7400th batch is: 7.034341\n","the loss in 7600th batch is: 7.834929\n","the loss in 7800th batch is: 7.814342\n","the loss in 8000th batch is: 7.215117\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 3709.200000\n","clicks hr ndcg @ 5 : 0.108625, 0.078289\n","purchase hr and ndcg @5 : 0.215271, 0.163412\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 4867.800000\n","clicks hr ndcg @ 10 : 0.145166, 0.090085\n","purchase hr and ndcg @10 : 0.270837, 0.181303\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 5576.200000\n","clicks hr ndcg @ 15 : 0.167456, 0.095976\n","purchase hr and ndcg @15 : 0.305046, 0.190354\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 6086.600000\n","clicks hr ndcg @ 20 : 0.183913, 0.099867\n","purchase hr and ndcg @20 : 0.327915, 0.195785\n","#############################################################\n","the loss in 8200th batch is: 8.092360\n","the loss in 8400th batch is: 7.561226\n","the loss in 8600th batch is: 7.532238\n","the loss in 8800th batch is: 7.610758\n","the loss in 9000th batch is: 7.646406\n","the loss in 9200th batch is: 7.214085\n","the loss in 9400th batch is: 7.350349\n","the loss in 9600th batch is: 7.891498\n","the loss in 9800th batch is: 7.206188\n","the loss in 10000th batch is: 7.115102\n","the loss in 10200th batch is: 7.547597\n","the loss in 10400th batch is: 7.756346\n","the loss in 10600th batch is: 6.988309\n","the loss in 10800th batch is: 7.361443\n","the loss in 11000th batch is: 6.640930\n","the loss in 11200th batch is: 6.789293\n","the loss in 11400th batch is: 7.077157\n","the loss in 11600th batch is: 6.892582\n","the loss in 11800th batch is: 6.995524\n","the loss in 12000th batch is: 6.652551\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 4296.000000\n","clicks hr ndcg @ 5 : 0.126367, 0.091579\n","purchase hr and ndcg @5 : 0.246834, 0.186439\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 5685.000000\n","clicks hr ndcg @ 10 : 0.170363, 0.105775\n","purchase hr and ndcg @10 : 0.312606, 0.207734\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 6540.600000\n","clicks hr ndcg @ 15 : 0.197184, 0.112880\n","purchase hr and ndcg @15 : 0.354375, 0.218802\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 7123.000000\n","clicks hr ndcg @ 20 : 0.215923, 0.117310\n","purchase hr and ndcg @20 : 0.380646, 0.225018\n","#############################################################\n","the loss in 12200th batch is: 7.125544\n","the loss in 12400th batch is: 6.914729\n","the loss in 12600th batch is: 7.037668\n","the loss in 12800th batch is: 7.197231\n","the loss in 13000th batch is: 6.919659\n","the loss in 13200th batch is: 6.777108\n","the loss in 13400th batch is: 7.069657\n","the loss in 13600th batch is: 6.520483\n","the loss in 13800th batch is: 6.862355\n","the loss in 14000th batch is: 6.682276\n","the loss in 14200th batch is: 6.461475\n","the loss in 14400th batch is: 6.968680\n","the loss in 14600th batch is: 6.900246\n","the loss in 14800th batch is: 6.653723\n","the loss in 15000th batch is: 6.747012\n","the loss in 15200th batch is: 6.632539\n","the loss in 15400th batch is: 6.731087\n","the loss in 15600th batch is: 6.415545\n","the loss in 15800th batch is: 6.404160\n","the loss in 16000th batch is: 6.762593\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 4567.800000\n","clicks hr ndcg @ 5 : 0.133205, 0.096432\n","purchase hr and ndcg @5 : 0.267624, 0.202607\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 6045.200000\n","clicks hr ndcg @ 10 : 0.180895, 0.111811\n","purchase hr and ndcg @10 : 0.333585, 0.223895\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 6957.400000\n","clicks hr ndcg @ 15 : 0.211418, 0.119893\n","purchase hr and ndcg @15 : 0.369495, 0.233381\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 7609.000000\n","clicks hr ndcg @ 20 : 0.231983, 0.124749\n","purchase hr and ndcg @20 : 0.400680, 0.240760\n","#############################################################\n","the loss in 16200th batch is: 6.063588\n","the loss in 16400th batch is: 6.496068\n","the loss in 16600th batch is: 6.740500\n","the loss in 16800th batch is: 6.707363\n","the loss in 17000th batch is: 6.354752\n","the loss in 17200th batch is: 6.322813\n","the loss in 17400th batch is: 6.517054\n","the loss in 17600th batch is: 6.102177\n","the loss in 17800th batch is: 6.488920\n","the loss in 18000th batch is: 6.207583\n","the loss in 18200th batch is: 6.527901\n","the loss in 18400th batch is: 5.815973\n","the loss in 18600th batch is: 6.387645\n","the loss in 18800th batch is: 6.102062\n","the loss in 19000th batch is: 6.056717\n","the loss in 19200th batch is: 6.089770\n","the loss in 19400th batch is: 6.238758\n","the loss in 19600th batch is: 6.301485\n","the loss in 19800th batch is: 6.573911\n","the loss in 20000th batch is: 6.055934\n","#############################################################\n","total clicks: 118306, total purchase:5291\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 5: 4745.600000\n","clicks hr ndcg @ 5 : 0.139367, 0.100247\n","purchase hr and ndcg @5 : 0.273672, 0.208512\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 10: 6250.000000\n","clicks hr ndcg @ 10 : 0.188156, 0.115981\n","purchase hr and ndcg @10 : 0.339822, 0.229933\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 15: 7248.000000\n","clicks hr ndcg @ 15 : 0.219135, 0.124185\n","purchase hr and ndcg @15 : 0.389907, 0.243172\n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","cumulative reward @ 20: 7928.200000\n","clicks hr ndcg @ 20 : 0.241290, 0.129420\n","purchase hr and ndcg @20 : 0.419391, 0.250134\n","#############################################################\n","the loss in 20200th batch is: 6.371142\n","the loss in 20400th batch is: 5.912626\n","the loss in 20600th batch is: 5.840269\n","the loss in 20800th batch is: 5.978428\n","the loss in 21000th batch is: 5.909127\n","the loss in 21200th batch is: 6.438307\n","the loss in 21400th batch is: 6.344915\n","the loss in 21600th batch is: 6.133871\n","the loss in 21800th batch is: 5.747736\n","the loss in 22000th batch is: 5.898430\n","the loss in 22200th batch is: 5.921380\n","the loss in 22400th batch is: 5.674768\n","the loss in 22600th batch is: 5.766466\n","the loss in 22800th batch is: 6.555138\n","the loss in 23000th batch is: 5.904083\n"]}],"source":["! python SNQN_AddFeatures_new.py --model=GRU --epoch=6 --mix_lambda=0.5"]},{"cell_type":"code","source":[],"metadata":{"id":"gy6DZ9job-To"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}